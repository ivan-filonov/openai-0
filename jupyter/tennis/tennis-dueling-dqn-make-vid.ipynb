{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### based on https://github.com/higgsfield/RL-Adventure and https://medium.com/swlh/introduction-to-reinforcement-learning-coding-sarsa-part-4-2d64d6e37617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "import cv2\n",
    "import gym\n",
    "import gzip\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch as t\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyFrames(object):\n",
    "    def __init__(self, frames):\n",
    "        \"\"\"This object ensures that common frames between the observations are only stored once.\n",
    "        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n",
    "        buffers.\n",
    "        This object should only be converted to numpy array before being passed to the model.\n",
    "        You'd not belive how complex the previous solution was.\"\"\"\n",
    "        self._frames = frames\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        out = np.concatenate(self._frames, axis=0)\n",
    "        if dtype is not None:\n",
    "            out = out.astype(dtype)\n",
    "        return out\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Change image shape to CWH\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]))\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return observation.transpose(2, 0, 1)\n",
    "    \n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env, k):\n",
    "        \"\"\"Stack k last frames.\n",
    "        Returns lazy array, which is much more memory efficient.\n",
    "        See Also\n",
    "        --------\n",
    "        baselines.common.atari_wrappers.LazyFrames\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.frames = collections.deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(shp[0]*k, shp[1], shp[2]))\n",
    "\n",
    "    def reset(self):\n",
    "        ob = self.env.reset()\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(ob)\n",
    "        return self._get_ob()\n",
    "\n",
    "    def step(self, action):\n",
    "        ob, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(ob)\n",
    "        return self._get_ob(), reward, done, info\n",
    "\n",
    "    def _get_ob(self):\n",
    "        assert len(self.frames) == self.k\n",
    "        return LazyFrames(list(self.frames))\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ResizeObservation, self).__init__(env)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(shp[0] // 2, shp[1] // 2, shp[2]))\n",
    "        self.resize_to = (shp[1] // 2, shp[0] // 2)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return cv2.resize(observation, self.resize_to, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "env = gym.make('TennisDeterministic-v4')\n",
    "env = gym.wrappers.Monitor(env, '.', force=True)\n",
    "env = ResizeObservation(env)\n",
    "env = ImageToPyTorch(env)\n",
    "env = FrameStack(env, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = t.cuda.is_available()# and False\n",
    "device = t.device('cuda') if USE_CUDA else t.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "def build_model():\n",
    "    return models.DuelingCnnDqn(env.observation_space.shape, env.action_space.n).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model weights loaded from model-dueling-cnn-dqn.gz\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "MODEL_PATH = f'model-{model.model_type()}.gz'\n",
    "with gzip.open(MODEL_PATH, 'rb') as f:\n",
    "    model.load_state_dict(t.load(f))\n",
    "print(f'model weights loaded from {MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b4d06586574db78763e7a36a39bf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps = 100000, rewards = 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba6c0df38594b62ae011aae6d8ee547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps = 100000, rewards = 0.0\n",
      "total 66M\r\n",
      "-rw-rw-r-- 1 user user  26M May 11 15:46 model-dueling-cnn-dqn.gz\r\n",
      "-rw-rw-r-- 1 user user 3.5M May 11 16:11 model-master-dueling-cnn-dqn.gz\r\n",
      "-rw-rw-r-- 1 user user  26M May 11 16:11 model-slave-dueling-cnn-dqn.gz\r\n",
      "-rw-rw-r-- 1 user user 1.2K May 11 10:11 models.py\r\n",
      "-rw-rw-r-- 1 user user  200 May 11 16:29 openaigym.episode_batch.0.30663.stats.json\r\n",
      "-rw-rw-r-- 1 user user  330 May 11 16:29 openaigym.manifest.0.30663.manifest.json\r\n",
      "-rw-rw-r-- 1 user user 2.1K May 11 16:23 openaigym.video.0.30663.video000000.meta.json\r\n",
      "-rw-rw-r-- 1 user user 5.1M May 11 16:23 openaigym.video.0.30663.video000000.mp4\r\n",
      "-rw-rw-r-- 1 user user 2.1K May 11 16:29 openaigym.video.0.30663.video000001.meta.json\r\n",
      "-rw-rw-r-- 1 user user 5.1M May 11 16:29 openaigym.video.0.30663.video000001.mp4\r\n",
      "drwxrwxr-x 2 user user 4.0K May 11 10:11 __pycache__\r\n",
      "-rw-rw-r-- 1 user user  47K May 11 16:27 tennis-dueling-dqn.ipynb\r\n",
      "-rw-rw-r-- 1 user user 7.9K May 11 16:25 tennis-dueling-dqn-make-vid.ipynb\r\n",
      "-rw-rw-r-- 1 user user  84K May 11 16:29 tennis-hier-dqn.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for _ in range(2):\n",
    "    steps, rewards = 0, 0\n",
    "    state, done = env.reset(), False\n",
    "    for _ in tqdm_notebook(range(100000)):\n",
    "        if random.random() > 0.05:\n",
    "            state = t.FloatTensor(np.array(state)).to(device)\n",
    "            action = model(state).argmax().item()\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        steps += 1\n",
    "        rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "    print(f'steps = {steps}, rewards = {rewards}')\n",
    "\n",
    "env.close()\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm openaigym.*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
